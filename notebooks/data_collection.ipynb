{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<div style = 'background-color:#1DB954;'>\n",
    "    <br>\n",
    "    <h3 style=\"color:black; margin-left:20px; margin-top:5px\"> CLASSICAL MUSIC RECOMMENDATIONS </h3>\n",
    "    <p style=\"color:black; margin-left:20px; margin-top:5px\"> Data Collection </p>\n",
    "    <br>\n",
    "</div>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import os.path\n",
    "import os \n",
    "import time \n",
    "import requests\n",
    "import sys \n",
    "import importlib\n",
    "\n",
    "import librosa\n",
    "import spotipy \n",
    "import spotipy.oauth2 as oauth2\n",
    "from spotipy.oauth2 import SpotifyOAuth \n",
    "from spotipy.oauth2 import SpotifyClientCredentials "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Adding the scripts folder into the path so that we can import modules\n",
    "sys.path.append('../scripts')\n",
    "\n",
    "# Importing functions from GSA script\n",
    "import GSA\n",
    "\n",
    "# Importing credentials from spotifyConstrants script \n",
    "import spotifyConstants\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Establishing Spotify connection \n",
    "\n",
    "# Setting up authorization manager (link to my Spotify Developer account) \n",
    "auth = SpotifyClientCredentials(client_id=spotifyConstants.myClientID, \n",
    "                                client_secret=spotifyConstants.myClientSecret)  \n",
    "\n",
    "sp = spotipy.Spotify(auth_manager=auth)\n",
    "\n",
    "# Authenticate to access Spotify API through Spotipy\n",
    "GSA.authenticate()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Building initial dataset \n",
    "\n",
    "# Importing composers dataset \n",
    "composers = pd.read_excel('Composers.xlsx')\n",
    "\n",
    "# Compiling information from all Playlists \n",
    "\n",
    "# Creating empty dataframe \n",
    "data = pd.DataFrame(columns=['Composer', 'playlistID', 'TrackName', 'TrackID', 'SampleURL', 'ReleaseYear',\n",
    "                             'Genres', 'danceability', 'energy', 'loudness', 'speechiness', 'acousticness',\n",
    "                             'instrumentalness', 'liveness', 'valence', 'tempo', 'key', 'mode', 'duration_ms',\n",
    "                             'Popularity'])\n",
    "\n",
    "for i in range(0, len(composers)):\n",
    "\n",
    "    # Track progress \n",
    "    print(i)\n",
    "\n",
    "    # Get composer \n",
    "    composer = composers.iloc[i, 0]\n",
    "\n",
    "    # Get playlist URI \n",
    "    uri = composers.iloc[i, 2]\n",
    "\n",
    "    # Obtain plylist information \n",
    "    playlist_info = GSA.getInformation(uri)\n",
    "\n",
    "    # Turn into dataframe \n",
    "    playlist_info_df = pd.read_pickle(playlist_info)\n",
    "\n",
    "    # Combine with composer name \n",
    "    composer_df = pd.DataFrame({'Composer': [composer] * len(playlist_info_df)})\n",
    "    playlist_info_df = pd.concat([composer_df, playlist_info_df], axis=1)\n",
    "\n",
    "    # Adding to overall dataframe \n",
    "    data = pd.concat([data, playlist_info_df]).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import dataframe \n",
    "\n",
    "len(data[data.SampleURL.isnull()])\n",
    "# There's 188 missing samples so those rows will be removed  \n",
    "\n",
    "data.dropna(subset=[\"SampleURL\"], inplace=True)\n",
    "data = data.reset_index(drop=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Obtaining mp3 samples (~30 minutes)\n",
    "\n",
    "toDownload = data[['SampleURL', 'TrackName', 'TrackID', 'playlistID']].values.tolist()\n",
    "\n",
    "# Create an array to keep track of which were successfully downloaded\n",
    "downloaded = []\n",
    "\n",
    "# Now download preview MP3s, in a loop\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "\n",
    "for track in toDownload:\n",
    "    \n",
    "    success = GSA.downloadTracks(track)\n",
    "    downloaded.append(success)\n",
    "    \n",
    "    #to keep track of progress\n",
    "    counter += 1 \n",
    "    if counter % 10 == 0:\n",
    "        print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Trimming wav files \n",
    "\n",
    "from scipy.io import wavfile\n",
    "\n",
    "file_names = os.listdir('wav')\n",
    "\n",
    "# the timestamp to split at (in seconds)\n",
    "timestamp_start = 5\n",
    "timestamp_end = 15\n",
    "\n",
    "for filename in file_names:\n",
    "    \n",
    "    if filename == '.DS_Store':\n",
    "        continue \n",
    "\n",
    "    # read the file and get the sample rate and data (create an empty wav folder)\n",
    "    rate, data = wavfile.read('wav/' + filename) \n",
    "\n",
    "    # get the frame to split at\n",
    "    split_start = rate * timestamp_start\n",
    "    split_end = rate * timestamp_end\n",
    "\n",
    "    # split\n",
    "    sample = data[split_start:split_end-1]  # split\n",
    "\n",
    "    # save the result\n",
    "    wavfile.write('wav_red/'+filename, rate, sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting audio features \n",
    "\n",
    "# Dataframe column names \n",
    "colnames = ['filename', 'chroma_stft', 'spectral_centroid', 'spectral_bandwidth', 'rolloff', 'zero_crossing_rate']\n",
    "for i in range(1, 21):\n",
    "    colnames.append('mfcc'+str(i))\n",
    "\n",
    "# Creating empty dataframe \n",
    "audio_features = pd.DataFrame(columns=colnames) \n",
    "\n",
    "# Getting filenames in the wav folder \n",
    "file_names = os.listdir('wav_red')\n",
    "\n",
    "counter = 0 \n",
    "\n",
    "# Looping through filenames\n",
    "for filename in file_names:\n",
    "    \n",
    "    if filename == '.DS_Store':\n",
    "        continue \n",
    "    \n",
    "    # to keep track of progress\n",
    "    counter += 1 \n",
    "    if counter % 10 == 0:\n",
    "        print(counter)\n",
    "        \n",
    "    y, sr = librosa.load('wav_red/' + filename)\n",
    "    \n",
    "    # Obtaining audio features \n",
    "    chroma_stft = librosa.feature.chroma_stft(y=y, sr=sr)\n",
    "    spec_cent = librosa.feature.spectral_centroid(y=y, sr=sr)\n",
    "    spec_bw = librosa.feature.spectral_bandwidth(y=y, sr=sr)\n",
    "    rolloff = librosa.feature.spectral_rolloff(y=y, sr=sr)\n",
    "    zcr = librosa.feature.zero_crossing_rate(y)\n",
    "    mfcc = librosa.feature.mfcc(y=y, sr=sr)\n",
    "    values = [filename, np.mean(chroma_stft), np.mean(spec_cent), np.mean(spec_bw), np.mean(rolloff), np.mean(zcr)]   \n",
    "    for e in mfcc:\n",
    "        values.append(np.mean(e))\n",
    "\n",
    "    \n",
    "    # Adding row to dataframe \n",
    "    df_length = len(audio_features)\n",
    "    audio_features.loc[len(audio_features)] = values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Combining with data df\n",
    "\n",
    "# audio features dataframe back up \n",
    "audio_features_bu = audio_features.copy()\n",
    "\n",
    "# Extracting TrackIDs from filenames \n",
    "audio_features['TrackID'] = audio_features.filename.apply(lambda st: st[st.find(\"ID_\")+3:st.find(\".wav\")])\n",
    "\n",
    "# Merging \n",
    "data = pd.merge(data, audio_features, 'left', on='TrackID')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Finalizing Dataframe \n",
    "\n",
    "data = pd.merge(data, composers[['Last Name', 'Born']], 'left', left_on='Composer', right_on='Last Name')\n",
    "\n",
    "# Removing irrelevant columns \n",
    "data = data.drop(columns=['playlistID', 'SampleURL', 'ReleaseYear', \\\n",
    "                          'speechiness', 'liveness', 'Genres', 'filename', 'Last Name'])\n",
    "\n",
    "# Removing Albinoni because only 4 pieces came through \n",
    "data = data[data['Composer']!='Albinoni']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating some additional features \n",
    "\n",
    "data['Symphony'] = data[\"TrackName\"].map(lambda x: 1 if \"Symphony\" in x else 0)\n",
    "data['Concerto'] = data[\"TrackName\"].map(lambda x: 1 if \"Concerto\" in x else 0)\n",
    "data['Quartet'] = data[\"TrackName\"].map(lambda x: 1 if \"Quartet\" in x else 0)\n",
    "data['Trio'] = data[\"TrackName\"].map(lambda x: 1 if \"Trio\" in x else 0)\n",
    "data['Sonata'] = data[\"TrackName\"].map(lambda x: 1 if \"Sonata\" in x else 0)\n",
    "\n",
    "# Saving as an excel file \n",
    "data.to_excel(\"Data_Final.xlsx\",  index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "cmr-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
